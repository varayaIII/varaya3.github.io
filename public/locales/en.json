{
  "nav_home": "Home",
  "nav_about": "About Me",
  "nav_projects": "Projects",
  "nav_blog": "Blog",
  "nav_contact": "Contact",
  "hero_title": "Víctor Araya",
  "hero_subtitle": "DevOps Engineer",
  "hero_description": "Building reliable and scalable systems through automation, infrastructure as code, and a collaborative culture.",
  "projects_title": "Featured Projects",
  "blog_title": "Latest Posts",
  "contact_title": "Contact",
  "project_cicd_title": "CI/CD Pipeline with GitHub Actions",
  "project_cicd_desc": "Automates the deployment of this portfolio through a CI/CD pipeline using GitHub Actions.",
  "project_security_title": "Automated Security (DevSecOps)",
  "project_security_desc": "Integrates vulnerability and secret scanning into the pipeline to secure code and containers.",
  "project_iac_title": "Infrastructure as Code",
  "project_iac_desc": "Implementation of cloud infrastructure using Terraform and AWS for automated deployments.",
  "project_python_title": "Automation with Python",
  "project_python_desc": "Creation of tools and scripts in Python for cloud resource management and task automation.",
  "project_k8s_title": "Kubernetes Cluster",
  "project_k8s_desc": "Configuration and management of a Kubernetes cluster for containerized applications.",
  "project_monitoring_title": "Systems Monitoring",
  "project_monitoring_desc": "Prometheus, Grafana, and Alertmanager stack for distributed infrastructure.",
  "about_page_title": "About Me - Víctor Araya",
  "about_main_title": "My Work Philosophy",
  "about_p1": "I'm Víctor Araya, a family man and a self-taught systems engineer focused on the Cloud ecosystem. My journey in technology has taught me a fundamental lesson: the most robust systems are not those that never fail, but those designed to be resilient, observable, and able to recover quickly.",
  "about_subtitle1": "From the \"How\" to the \"Why\"",
  "about_p2": "My passion for DevOps was born from a curiosity to go beyond simply executing tasks. Instead of asking, \"how do I deploy this application?\", I began to wonder, \"how do we build a system that allows for safe, automated deployments at any time with minimal human intervention?\".",
  "about_p3": "This question led me to delve into the principles of Infrastructure as Code (IaC), continuous delivery (CI/CD), and observability. I see technology not as an end in itself, but as a means to achieve crucial business objectives: agility, stability, and trust.",
  "about_subtitle2": "Culture of Continuous Improvement",
  "about_p4": "I adopt an iterative improvement mindset in everything I do. I firmly believe that automation is the key to unlocking human potential, allowing teams to focus on innovation rather than crisis management. To me, a well-designed CI/CD pipeline or an idempotent Terraform script are more than just tools; they are the embodiment of a culture that values consistency, predictability, and collaboration.",
  "about_back_button": "← Back to home",
  "blog_fundamentos_title": "Foundations",
  "blog_fundamentos_excerpt": "Exploring the essential concepts of Kubernetes and how to apply them in Site Reliability Engineering environments…",
  "blog_automatizacion_title": "Automation",
  "blog_automatizacion_excerpt": "How to implement infrastructure as code using Terraform to manage resources across multiple clouds…",
  "blog_monitoreo_title": "Monitoring",
  "blog_monitoreo_excerpt": "Advanced Prometheus configuration for monitoring distributed systems and effective alerting strategies…",
  "blog_read_more": "Read more",
  "form_name": "Name",
  "form_email": "Email",
  "form_message": "Leave your message",
  "form_send": "Send",
  "form_success_message": "<div class='alert alert-success mb-0' role='alert'>Thank you! Your message has been sent successfully.</div>",
  "form_error_message": "<div class='alert alert-danger mb-0' role='alert'>Could not send the message. Please try again later.</div>",
  "footer_copyright": "© {year} Varaya Labs. All rights reserved.",
  "project_view_on_github": "View on GitHub",
  "post_published_on": "Published on ",
  "post_back_to_blog": "← Back to blog",
  "post_automatizacion_title": "DevOps Automation: From Infrastructure to Deployment",
  "post_automatizacion_body": "<p class='lead'>Automation is the heart that pumps blood through the veins of DevOps and SRE. It's the principle that allows us to build consistent, repeatable, and scalable systems, freeing us from error-prone manual tasks.</p><h2 class='mt-4'>Infrastructure as Code (IaC): The Foundation</h2><p>Gone are the days of manually provisioning servers through web consoles. With IaC, we define our infrastructure (servers, databases, networks) in code files. My principles when using tools like Terraform are:</p><ul><li><strong>Modularization:</strong> I don't write one giant Terraform file for everything. I break down the infrastructure into logical, reusable modules (e.g., a module for the network, another for the database). This makes the code cleaner and easier to maintain.</li><li><strong>Reusability:</strong> Thanks to modules, I can create a new, complete environment (like staging or development) in minutes, knowing it will be an exact replica of production.</li><li><strong>Remote State Handling:</strong> Terraform needs a state file to know what infrastructure it has created. Storing this state remotely (in an S3 bucket, for example) and with locking is crucial for teamwork without conflicts.</li></ul><p class='text-center'><img src='../../public/assets/automatizacion-1.png' class='img-fluid rounded my-3' alt='Infrastructure as Code (IaC) diagram with Terraform and AWS.'><small class='text-muted d-block mb-2'>Defining the cloud with versioned code.</small></p><h2 class='mt-4'>CI/CD Pipelines: The Assembly Line</h2><p>A CI/CD pipeline is an automated assembly line that takes code from the repository to production. Every change triggers a process that I structure into clear phases:</p><ol><li><strong>Build:</strong> The code is compiled and, more commonly today, a container image (Docker) is built. The result is an immutable artifact.</li><li><strong>Test:</strong> Automated tests (unit, integration) are run against the newly created artifact to ensure we haven't broken anything.</li><li><strong>Security:</strong> Security is non-negotiable! I integrate vulnerability (Trivy, Snyk) and secret scanning (GitLeaks) tools to detect issues before they reach production (Shift-Left Security).</li><li><strong>Deploy:</strong> If all previous stages (or quality gates) pass, the pipeline deploys the artifact to the different environments (Dev, Staging, Prod) using safe strategies like Blue-Green or Canary.</li></ol><p class='text-center'><img src='../../public/assets/automatizacion-2.png' class='img-fluid rounded my-3' alt='Typical CI/CD pipeline diagram with Build, Test, Security and Deploy stages.'><small class='text-muted d-block mb-2'>The automated path from code to production.</small></p><h2 class='mt-4'>Reliable Operation: Fail-Safe Deployments</h2><p>Reaching production is only half the journey. Automation is also key to operating reliably. I use techniques like feature flags to gradually and safely activate new features, and I have automated rollback processes to revert a failed deployment in seconds, minimizing user impact.</p>",
  "post_fundamentos_title": "SRE/DevOps Foundations: Key Concepts to Get Started",
  "post_fundamentos_body": "<p class='lead'>Every great journey begins with a single step, and in the world of DevOps and SRE, that step is understanding the fundamental concepts that underpin everything else.</p><h2 class='mt-4'>What Problem Do These Methodologies Solve?</h2><p>Historically, software development (Dev) and systems operation (Ops) lived in separate worlds, often with conflicting goals. Developers want to release new features quickly, while operations seeks stability. This friction created silos, bottlenecks, and ultimately delayed value delivery.</p><p class='text-center'><img src='../../public/assets/fundamentos-1.png' class='img-fluid rounded my-3' alt='Diagram of silos between Dev and Ops, and how DevOps unites them.'><small class='text-muted d-block mb-2'>From isolated silos to collaborative teams.</small></p><h2 class='mt-4'>Key Concepts You Must Master</h2><p>To think like an SRE/DevOps engineer, certain concepts must become part of your DNA:</p><ul><li><strong>Declarative vs. Imperative:</strong> Imagine you want a coffee. The imperative approach would be to give step-by-step instructions: 'go to the kitchen, get the cup, open the jar, add a spoonful...'. The declarative approach is simply to say: 'I want a coffee'. You declare the desired final state, and the tool (like Terraform or Kubernetes) handles the steps to get there.</li></ul><p class='text-center'><img src='../../public/assets/fundamentos-2.png' class='img-fluid rounded my-3' alt='Diagram comparing the declarative and imperative approaches.'><small class='text-muted d-block mb-2'>You declare the 'what', not the 'how'.</small></p><ul><li><strong>Idempotency:</strong> This is a crucial property for safe automation. It means you can run the same operation over and over, and the result will always be the same. Applying a Terraform script 10 times doesn't create 10 infrastructures; it ensures the infrastructure is in the state defined by the code.</li><li><strong>Immutability:</strong> This concept, applied to infrastructure, means: 'never modify a server in production; replace it'. If you need to update an application, you don't log into the server to change files. Instead, you create a new version of the server image and deploy it, discarding the old one. This prevents 'configuration drift' and makes systems more predictable.</li></ul><h2 class='mt-4'>Best Practices to Start on the Right Foot</h2><ul><li><strong>Version Everything (GitOps):</strong> Your application code is already in Git, right? Well, your infrastructure (Terraform), your pipeline configuration (GitHub Actions), and your Kubernetes manifests should be too. Git becomes the single source of truth.</li><li><strong>Automate Testing and Deployment (CI/CD):</strong> Continuous Integration (CI) and Continuous Delivery (CD) are the engine of DevOps. Every code change should trigger an automated process that builds, tests, and deploys safely.</li><li><strong>Minimum Viable Observability:</strong> You can't improve what you can't measure. From day one, ensure you have at least the three pillars of observability: <strong>Metrics</strong> (numerical data), <strong>Logs</strong> (events), and <strong>Traces</strong> (request flows).</li></ul><p class='text-center'><img src='../../public/assets/fundamentos-3.png' class='img-fluid rounded my-3' alt='Diagram of the three pillars of observability (Metrics, Logs, Traces).'><small class='text-muted d-block mb-2'>The three pillars for understanding your system.</small></p>",
  "post_monitoreo_title": "Actionable Monitoring: Metrics, Alerts, and Dashboards",
  "post_monitoreo_body": "<p class='lead'>Monitoring is not about collecting data and pretty graphs. It's about gaining actionable visibility into the health of your systems to make informed decisions, anticipate problems, and respond to incidents effectively.</p><h2 class='mt-4'>Metric Design: Quality Over Quantity</h2><p>With Prometheus, the foundation is metrics and their labels. A poor design here can lead to a slow, expensive, and hard-to-use monitoring system. My two golden rules:</p><ul><li><strong>Controlled Cardinality:</strong> Cardinality is the number of unique time series a metric generates. It's calculated by the combination of labels. Using labels with unique values for each user or request (like a `user_id` or `request_id`) is a recipe for disaster. Keep labels for low-cardinality dimensions: `endpoint`, `http_method`, `status_code`.</li><li><strong>Labels that Provide Context:</strong> Labels are superpowers. They allow you to aggregate, filter, and segment data. A good label helps you go from 'latency is high' to 'latency is high for the POST method on the payments service'.</li></ul><p class='text-center'><img src='../../public/assets/monitoreo-1.png' class='img-fluid rounded my-3' alt='Diagram showing how metric labels affect cardinality in Prometheus.'><small class='text-muted d-block mb-2'>The right labels for efficient queries.</small></p><h2 class='mt-4'>Useful Alerts: Less Noise, More Signal</h2><p>The purpose of an alert is not to say 'something is wrong', but 'something requires your attention NOW'. My approach with Alertmanager is to reduce noise at all costs:</p><ul><li><strong>Routes and Receivers:</strong> Not all alerts are equal or should go to the same place. Critical alerts (`severity=critical`) can go to PagerDuty and a noisy Slack channel. Warnings (`severity=warning`) might only go to Slack, and informational ones to an email.</li><li><strong>Clear Severities:</strong> I classify alerts into severity levels (`critical`, `warning`, `info`) so the team knows what requires immediate action and what can wait.</li><li><strong>Grouping and Silences:</strong> If 50 servers in a cluster have the same problem, you don't want 50 alerts. Alertmanager groups these alerts by labels (`cluster`, `service`) into a single notification. It also allows creating 'silences' to suppress alerts during planned maintenance.</li></ul><p class='text-center'><img src='../../public/assets/monitoreo-2.png' class='img-fluid rounded my-3' alt='Alertmanager workflow diagram: how it groups and routes alerts.'><small class='text-muted d-block mb-2'>Routing the right alert to the right person.</small></p><h2 class='mt-4'>Dashboards that Work: Telling a Story</h2><p>A Grafana dashboard should not be a graveyard of graphs. It should tell a clear story and guide the user from a high-level view (is everything okay?) to the specific details needed to diagnose a problem. I often structure them using the RED method (Rate, Errors, Duration) or USE method (Utilization, Saturation, Errors) to have a standardized view of service health.</p>"
}
